{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewjin/AICS-EXP/blob/main/colab_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÁéØÂ¢ÉÈÖçÁΩÆ environment"
      ],
      "metadata": {
        "id": "_o6a8GS2lWQM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9b7iFV3dm1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4420150-68c5-4b87-8615-8aef2460ade7"
      },
      "source": [
        "!pip install -q condacolab\n",
        "# Setting up condacolab and installing packages\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh\")\n",
        "%cd -q /content\n",
        "!git clone https://github.com/RVC-Boss/GPT-SoVITS\n",
        "!conda install -y -q -c pytorch -c nvidia cudatoolkit\n",
        "%cd -q /content/GPT-SoVITS\n",
        "!conda install -y -q -c conda-forge gcc gxx ffmpeg cmake -c pytorch -c nvidia\n",
        "!/usr/local/bin/pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n",
            "fatal: destination path 'GPT-SoVITS' already exists and is not an empty directory.\n",
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:201: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "\n",
            "CondaValueError: You have chosen a non-default solver backend (libmamba) but it was not recognized. Choose one of: classic\n",
            "\n",
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:201: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "\n",
            "CondaValueError: You have chosen a non-default solver backend (libmamba) but it was not recognized. Choose one of: classic\n",
            "\n",
            "Ignoring onnxruntime: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring opencc: markers 'sys_platform != \"linux\"' don't match your environment\n",
            "Requirement already satisfied: numpy==1.23.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.19.0)\n",
            "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.9.2)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.56.4)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.5.0.post0)\n",
            "Requirement already satisfied: gradio<=4.24.0,>=4.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.24.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.19.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (4.67.1)\n",
            "Requirement already satisfied: funasr==1.0.27 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.0.27)\n",
            "Requirement already satisfied: cn2an in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (0.5.23)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (0.53.0)\n",
            "Requirement already satisfied: pyopenjtalk>=0.3.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (0.4.0)\n",
            "Requirement already satisfied: g2p_en in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (2.1.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (2.6.0)\n",
            "Requirement already satisfied: modelscope==1.10.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (1.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (4.48.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (5.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (7.0.0)\n",
            "Requirement already satisfied: jieba_fast in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (0.53)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (0.42.1)\n",
            "Requirement already satisfied: split-lang in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 26)) (2.0.5)\n",
            "Requirement already satisfied: Faster_Whisper in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 27)) (1.1.1)\n",
            "Requirement already satisfied: wordsegment in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 28)) (1.3.1)\n",
            "Requirement already satisfied: rotary_embedding_torch in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 29)) (0.8.6)\n",
            "Requirement already satisfied: ToJyutping in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (3.2.0)\n",
            "Requirement already satisfied: g2pk2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (0.0.3)\n",
            "Requirement already satisfied: ko_pron in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 32)) (1.3)\n",
            "Requirement already satisfied: opencc==1.1.1 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 34)) (1.1.1)\n",
            "Requirement already satisfied: python_mecab_ko in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 35)) (1.3.7)\n",
            "Requirement already satisfied: fastapi<0.112.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 36)) (0.112.1)\n",
            "Requirement already satisfied: x_transformers in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (2.0.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/site-packages (from numba==0.56.4->-r requirements.txt (line 5)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from numba==0.56.4->-r requirements.txt (line 5)) (68.2.2)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (2.18.0)\n",
            "Requirement already satisfied: torch-complex in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: pytorch-wpe in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.0.1)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (2.19.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.5.7)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.4.0)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (2.6.2.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (20240930)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (25.1.0)\n",
            "Requirement already satisfied: datasets>=2.14.5 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (0.8.1)\n",
            "Requirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.17.0)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (0.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.2.3)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (10.4.0)\n",
            "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (19.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.32.3)\n",
            "Requirement already satisfied: simplejson>=3.3.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.20.1)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (1.26.18)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (5.29.3)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning->-r requirements.txt (line 6)) (2.6.0)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 6)) (2024.12.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning->-r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning->-r requirements.txt (line 6)) (0.12.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==0.14.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.9.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.10.15)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.9.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.34.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.9/site-packages (from gradio-client==0.14.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (11.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/site-packages (from ffmpeg-python->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: proces>=0.1.7 in /usr/local/lib/python3.9/site-packages (from cn2an->-r requirements.txt (line 13)) (0.1.7)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.9/site-packages (from g2p_en->-r requirements.txt (line 16)) (3.9.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.9/site-packages (from g2p_en->-r requirements.txt (line 16)) (7.5.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.9/site-packages (from g2p_en->-r requirements.txt (line 16)) (0.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.9/site-packages (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/site-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 20)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 20)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 20)) (0.5.2)\n",
            "Requirement already satisfied: fast-langdetect in /usr/local/lib/python3.9/site-packages (from split-lang->-r requirements.txt (line 26)) (0.2.5)\n",
            "Requirement already satisfied: budoux in /usr/local/lib/python3.9/site-packages (from split-lang->-r requirements.txt (line 26)) (0.6.4)\n",
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.9/site-packages (from split-lang->-r requirements.txt (line 26)) (3.1.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.9/site-packages (from Faster_Whisper->-r requirements.txt (line 27)) (4.5.0)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.9/site-packages (from Faster_Whisper->-r requirements.txt (line 27)) (1.19.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.9/site-packages (from Faster_Whisper->-r requirements.txt (line 27)) (14.1.0)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.9/site-packages (from python_mecab_ko->-r requirements.txt (line 35)) (2.1.1.post2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.9/site-packages (from fastapi<0.112.2->-r requirements.txt (line 36)) (0.38.6)\n",
            "Requirement already satisfied: einx>=0.3.0 in /usr/local/lib/python3.9/site-packages (from x_transformers->-r requirements.txt (line 37)) (0.3.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.9/site-packages (from x_transformers->-r requirements.txt (line 37)) (0.7.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.26.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (3.11.12)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.9/site-packages (from einx>=0.3.0->x_transformers->-r requirements.txt (line 37)) (2.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.9/site-packages (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/site-packages (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12)) (4.9.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.21.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.9/site-packages (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16)) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.9/site-packages (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16)) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (8.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 16)) (8.1.8)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 18)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/site-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 18)) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/site-packages (from pooch>=1.0->librosa==0.9.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.9/site-packages (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.9/site-packages (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 18)) (2.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa==0.9.2->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/site-packages (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 10)) (10.0)\n",
            "Requirement already satisfied: robust-downloader>=0.0.2 in /usr/local/lib/python3.9/site-packages (from fast-langdetect->split-lang->-r requirements.txt (line 26)) (0.0.2)\n",
            "Requirement already satisfied: fasttext-predict>=0.9.2.4 in /usr/local/lib/python3.9/site-packages (from fast-langdetect->split-lang->-r requirements.txt (line 26)) (0.9.2.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/site-packages (from openai-whisper->funasr==1.0.27->-r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (3.21.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (2.16.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.9/site-packages (from umap-learn->funasr==1.0.27->-r requirements.txt (line 12)) (0.5.13)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.9/site-packages (from wordfreq->split-lang->-r requirements.txt (line 26)) (6.3.1)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.9/site-packages (from wordfreq->split-lang->-r requirements.txt (line 26)) (3.5.0)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.9/site-packages (from wordfreq->split-lang->-r requirements.txt (line 26)) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.9/site-packages (from wordfreq->split-lang->-r requirements.txt (line 26)) (1.1.0)\n",
            "Requirement already satisfied: ipadic<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from wordfreq[cjk]->split-lang->-r requirements.txt (line 26)) (1.0.0)\n",
            "Requirement already satisfied: mecab-ko-dic<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from wordfreq[cjk]->split-lang->-r requirements.txt (line 26)) (1.0.0)\n",
            "Requirement already satisfied: mecab-python3<2.0.0,>=1.0.5 in /usr/local/lib/python3.9/site-packages (from wordfreq[cjk]->split-lang->-r requirements.txt (line 26)) (1.0.10)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.9/site-packages (from yapf->modelscope==1.10.0->-r requirements.txt (line 18)) (2.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (5.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (1.18.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.9/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.9/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12)) (41.0.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (2.21)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from ftfy>=6.1->wordfreq->split-lang->-r requirements.txt (line 26)) (0.2.13)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.22.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.9/site-packages (from langcodes>=3.0->wordfreq->split-lang->-r requirements.txt (line 26)) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.19.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/site-packages (from robust-downloader>=0.0.2->fast-langdetect->split-lang->-r requirements.txt (line 26)) (6.9.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.9/site-packages (from language-data>=1.2->langcodes>=3.0->wordfreq->split-lang->-r requirements.txt (line 26)) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download pretrained models ‰∏ãËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
        "!mkdir -p /content/GPT-SoVITS/GPT_SoVITS/pretrained_models\n",
        "!mkdir -p /content/GPT-SoVITS/tools/damo_asr/models\n",
        "!mkdir -p /content/GPT-SoVITS/tools/uvr5\n",
        "%cd /content/GPT-SoVITS/GPT_SoVITS/pretrained_models\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS\n",
        "%cd /content/GPT-SoVITS/tools/damo_asr/models\n",
        "!git clone https://www.modelscope.cn/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch.git\n",
        "# @title UVR5 pretrains ÂÆâË£Öuvr5Ê®°Âûã\n",
        "%cd /content/GPT-SoVITS/tools/uvr5\n",
        "%rm -r uvr5_weights\n",
        "!git clone https://huggingface.co/Delik/uvr5_weights\n",
        "!git config core.sparseCheckout true\n",
        "!mv /content/GPT-SoVITS/GPT_SoVITS/pretrained_models/GPT-SoVITS/* /content/GPT-SoVITS/GPT_SoVITS/pretrained_models/"
      ],
      "metadata": {
        "id": "0NgxXg5sjv7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be930147-7b8f-4950-b5a8-49d4085e447a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPT-SoVITS/GPT_SoVITS/pretrained_models\n",
            "fatal: destination path 'GPT-SoVITS' already exists and is not an empty directory.\n",
            "/content/GPT-SoVITS/tools/damo_asr/models\n",
            "fatal: destination path 'speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch' already exists and is not an empty directory.\n",
            "fatal: destination path 'speech_fsmn_vad_zh-cn-16k-common-pytorch' already exists and is not an empty directory.\n",
            "fatal: destination path 'punc_ct-transformer_zh-cn-common-vocab272727-pytorch' already exists and is not an empty directory.\n",
            "/content/GPT-SoVITS/tools/uvr5\n",
            "Cloning into 'uvr5_weights'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (15/15), 3.25 KiB | 1.08 MiB/s, done.\n",
            "Filtering content: 100% (9/9), 594.44 MiB | 61.07 MiB/s, done.\n",
            "mv: cannot stat '/content/GPT-SoVITS/GPT_SoVITS/pretrained_models/GPT-SoVITS/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U huggingface_hub\n",
        "!huggingface-cli download --resume-download FacebookAI/xlm-roberta-large --local-dir FacebookAI/xlm-roberta-large --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "eJDlet53y0-0",
        "outputId": "11a692fc-10e7-4cbf-cfdd-942e40af7570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.9/site-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->huggingface_hub) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "/usr/local/lib/python3.9/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Fetching 17 files:   0% 0/17 [00:00<?, ?it/s]Downloading '.gitattributes' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.02ad21b7d01294a7a4b7900ac62f12a81d118a66.incomplete'\n",
            "Downloading 'onnx/config.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/8_PA_wEVGiVa2goH2H4KQOQpvVY=.ebc8438f4984c23fe41d3459c8d1ab75ba2f5fcb.incomplete'\n",
            "Downloading 'onnx/model.onnx_data' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/k0JOJY4De220dP0y1LZKX-AzOvA=.1798dab29db9d3fe4193ffa091512730369bd1c1c2041de430e09394d4f57df1.incomplete'\n",
            "Downloading 'onnx/model.onnx' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/ihhw_uFzBe-Y54_HOJQmXx4GS8A=.bb5a52503a3ef35247f5b5ae6c473aaae60505dd3ffaef56d7b69e2f84683c05.incomplete'\n",
            "Downloading 'flax_model.msgpack' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/gPcsVCQDYDHk-_n0G9uADl7PXIM=.96d19a73ca044be7c23518d2d23154eb0a1e6fb301d3b086e2d80bdfff1391ce.incomplete'\n",
            "Downloading 'README.md' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.353e24dd8962783166f4ffc9841b57c62c3a9849.incomplete'\n",
            "Downloading 'config.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.8e5fb14e1352fd8fc678a7b293b63cfb5cf091f6.incomplete'\n",
            "Downloading 'model.safetensors' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.2dfa19f172412917cab174da04b46e2134811b723666965fd0aabd97caa6e23b.incomplete'\n",
            "\n",
            ".gitattributes: 100% 623/623 [00:00<00:00, 79.1kB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/.gitattributes\n",
            "\n",
            "onnx%2Fconfig.json: 100% 681/681 [00:00<00:00, 116kB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/onnx/config.json\n",
            "Fetching 17 files:   6% 1/17 [00:00<00:03,  4.56it/s]\n",
            "README.md: 100% 5.24k/5.24k [00:00<00:00, 851kB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/README.md\n",
            "\n",
            "model.safetensors:   0% 0.00/2.24G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:   0% 0.00/2.24G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.onnx:   0% 0.00/546k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "config.json: 100% 616/616 [00:00<00:00, 85.4kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   0% 0.00/2.24G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[ADownload complete. Moving file to FacebookAI/xlm-roberta-large/config.json\n",
            "Downloading 'onnx/sentencepiece.bpe.model' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/TXm7Ys-HnGKK11f8pj82ppdReFk=.cfc8146abe2a0488e9e2a0c56de7952f7c11ab059eca145a0a727afce0db2865.incomplete'\n",
            "Downloading 'onnx/special_tokens_map.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/ahkChHUJFxEmOdq5GDFEmerRzCY=.d5698132694f4f1bcff08fa7d937b1701812598e.incomplete'\n",
            "Downloading 'onnx/tokenizer.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.62c24cdc13d4c9952d63718d6c9fa4c287974249e16b7ade6d5a85e7bbb75626.incomplete'\n",
            "model.onnx: 100% 546k/546k [00:00<00:00, 6.92MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/onnx/model.onnx\n",
            "\n",
            "\n",
            "\n",
            "onnx%2Fspecial_tokens_map.json: 100% 280/280 [00:00<00:00, 129kB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/onnx/special_tokens_map.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   0% 10.5M/2.24G [00:00<00:29, 74.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "sentencepiece.bpe.model:   0% 0.00/5.07M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'pytorch_model.bin' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/Q1p2l2BzM1m6P5jKvr8WTq1TUio=.01e55aa45dbb9164fee19aef60007a1c91d175051c01be1fb15056cfa60f3e53.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/17.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'sentencepiece.bpe.model' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/TXm7Ys-HnGKK11f8pj82ppdReFk=.db9af13bf09fd3028ca32be90d3fb66d5e470399.incomplete'\n",
            "\n",
            "model.safetensors:   0% 10.5M/2.24G [00:00<01:01, 36.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 41.2MB/s]\u001b[A\u001b[A\u001b[ADownloading 'onnx/tokenizer_config.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/onnx/vzaExXFZNBay89bvlQv-ZcI6BTg=.6de1940d16d38be9877bf7cc228c9377841b311f.incomplete'\n",
            "\n",
            "\n",
            "flax_model.msgpack:   0% 10.5M/2.24G [00:00<01:06, 33.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 34.1MB/s]\n",
            "\n",
            "\n",
            "\n",
            "sentencepiece.bpe.model:   0% 0.00/5.07M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownload complete. Moving file to FacebookAI/xlm-roberta-large/onnx/sentencepiece.bpe.model\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   1% 31.5M/2.24G [00:00<00:24, 89.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "onnx%2Ftokenizer_config.json: 100% 418/418 [00:00<00:00, 183kB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/onnx/tokenizer_config.json\n",
            "Downloading 'tf_model.h5' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/a7eHxRFT3OeMBIFg52k2nfj5m7w=.a465c8d459fe83e10db5655221e2e7e7b6df3de2216c524399358d17ac7315ea.incomplete'\n",
            "\n",
            "\n",
            "flax_model.msgpack:   1% 21.0M/2.24G [00:00<00:45, 48.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:  61% 10.5M/17.1M [00:00<00:00, 35.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   2% 41.9M/2.24G [00:00<00:25, 85.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'tokenizer.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.463f3414782c1c9405828c9b31bfa36dda1f45c5.incomplete'\n",
            "\n",
            "model.safetensors:   1% 31.5M/2.24G [00:00<00:35, 61.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:   1% 31.5M/2.24G [00:00<00:36, 60.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   0% 10.5M/2.24G [00:00<00:54, 41.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   0% 0.00/2.24G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 17.1M/17.1M [00:00<00:00, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 17.1M/17.1M [00:00<00:00, 35.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   2% 52.4M/2.24G [00:00<00:29, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   2% 41.9M/2.24G [00:00<00:36, 60.0MB/s]\u001b[ADownload complete. Moving file to FacebookAI/xlm-roberta-large/onnx/tokenizer.json\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 12.2MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/sentencepiece.bpe.model\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   0% 10.5M/2.24G [00:00<00:29, 76.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   2% 41.9M/2.24G [00:00<00:42, 51.3MB/s]\u001b[A\u001b[ADownloading 'tokenizer_config.json' to 'FacebookAI/xlm-roberta-large/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.34ddbd64a4cd3f2d9d8a9120d3662d0bf91baead.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   1% 21.0M/2.24G [00:00<00:56, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer_config.json:   0% 0.00/25.0 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   2% 52.4M/2.24G [00:00<00:40, 53.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 384B/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/tokenizer_config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   1% 21.0M/2.24G [00:00<00:39, 56.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   1% 31.5M/2.24G [00:00<00:48, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   2% 52.4M/2.24G [00:01<00:44, 49.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   3% 73.4M/2.24G [00:01<00:32, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   3% 62.9M/2.24G [00:01<00:36, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   2% 41.9M/2.24G [00:00<00:38, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   1% 31.5M/2.24G [00:00<00:38, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   3% 62.9M/2.24G [00:01<00:39, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   4% 83.9M/2.24G [00:01<00:35, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   3% 73.4M/2.24G [00:01<00:39, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   2% 41.9M/2.24G [00:00<00:40, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   2% 52.4M/2.24G [00:01<00:41, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   3% 73.4M/2.24G [00:01<00:42, 50.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   4% 94.4M/2.24G [00:01<00:39, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 10.0MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/tokenizer.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   2% 52.4M/2.24G [00:01<00:45, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   3% 62.9M/2.24G [00:01<00:47, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   4% 83.9M/2.24G [00:01<00:44, 48.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   5% 105M/2.24G [00:01<00:39, 53.7MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   4% 94.4M/2.24G [00:01<00:42, 50.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   3% 62.9M/2.24G [00:01<00:39, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   3% 73.4M/2.24G [00:01<00:41, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   3% 73.4M/2.24G [00:01<00:33, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   4% 94.4M/2.24G [00:01<00:43, 49.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   5% 115M/2.24G [00:01<00:38, 55.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   5% 105M/2.24G [00:01<00:38, 55.1MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   4% 83.9M/2.24G [00:01<00:39, 54.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   5% 115M/2.24G [00:02<00:34, 62.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   4% 94.4M/2.24G [00:01<00:28, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   5% 105M/2.24G [00:02<00:44, 47.8MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   4% 94.4M/2.24G [00:01<00:38, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   6% 126M/2.24G [00:02<00:31, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   6% 126M/2.24G [00:02<00:43, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   5% 115M/2.24G [00:02<00:37, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   6% 136M/2.24G [00:02<00:38, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   6% 136M/2.24G [00:02<00:32, 65.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   5% 115M/2.24G [00:01<00:27, 76.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   6% 126M/2.24G [00:02<00:35, 59.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   5% 115M/2.24G [00:02<00:30, 68.8MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   7% 147M/2.24G [00:02<00:36, 57.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   7% 147M/2.24G [00:02<00:31, 67.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   6% 126M/2.24G [00:01<00:29, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   6% 136M/2.24G [00:02<00:37, 55.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   6% 126M/2.24G [00:02<00:35, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   7% 157M/2.24G [00:02<00:38, 54.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   7% 157M/2.24G [00:02<00:37, 55.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:   7% 147M/2.24G [00:02<00:35, 58.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   6% 136M/2.24G [00:02<00:32, 65.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   6% 136M/2.24G [00:02<00:33, 63.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   8% 168M/2.24G [00:02<00:36, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   7% 157M/2.24G [00:02<00:33, 61.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   7% 147M/2.24G [00:02<00:34, 61.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   7% 147M/2.24G [00:02<00:34, 60.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   7% 168M/2.24G [00:03<00:41, 49.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   8% 178M/2.24G [00:03<00:40, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   7% 157M/2.24G [00:02<00:33, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   7% 157M/2.24G [00:02<00:35, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   7% 168M/2.24G [00:03<00:42, 48.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   8% 178M/2.24G [00:03<00:43, 47.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   7% 168M/2.24G [00:02<00:32, 63.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   7% 168M/2.24G [00:03<00:36, 57.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   8% 189M/2.24G [00:03<00:43, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   8% 178M/2.24G [00:03<00:38, 53.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   8% 178M/2.24G [00:02<00:34, 59.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   8% 189M/2.24G [00:03<00:44, 45.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   9% 199M/2.24G [00:03<00:42, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   8% 178M/2.24G [00:03<00:41, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   8% 189M/2.24G [00:03<00:43, 47.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   9% 199M/2.24G [00:03<00:42, 47.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   8% 189M/2.24G [00:03<00:37, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:   9% 210M/2.24G [00:03<00:41, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   8% 189M/2.24G [00:03<00:40, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:   9% 199M/2.24G [00:03<00:42, 47.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   9% 210M/2.24G [00:03<00:42, 47.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   9% 199M/2.24G [00:03<00:37, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   9% 199M/2.24G [00:03<00:39, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  10% 220M/2.24G [00:03<00:41, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:   9% 210M/2.24G [00:03<00:37, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  10% 231M/2.24G [00:04<00:36, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  10% 220M/2.24G [00:04<00:43, 46.4MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:   9% 210M/2.24G [00:04<00:46, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:   9% 210M/2.24G [00:03<00:37, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  10% 220M/2.24G [00:03<00:32, 61.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  10% 220M/2.24G [00:03<00:33, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  10% 231M/2.24G [00:04<00:38, 52.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  11% 241M/2.24G [00:04<00:36, 54.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  10% 231M/2.24G [00:03<00:30, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  10% 231M/2.24G [00:04<00:29, 67.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  11% 241M/2.24G [00:04<00:33, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  11% 252M/2.24G [00:04<00:31, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  11% 241M/2.24G [00:03<00:33, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  11% 241M/2.24G [00:04<00:32, 62.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  11% 252M/2.24G [00:04<00:38, 52.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  12% 262M/2.24G [00:04<00:38, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  11% 252M/2.24G [00:04<00:31, 63.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  11% 252M/2.24G [00:04<00:34, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  12% 262M/2.24G [00:04<00:36, 53.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  12% 273M/2.24G [00:04<00:34, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  12% 262M/2.24G [00:04<00:33, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  12% 262M/2.24G [00:04<00:31, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  12% 273M/2.24G [00:05<00:35, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  13% 283M/2.24G [00:05<00:39, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  12% 273M/2.24G [00:04<00:36, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  10% 220M/2.24G [00:05<01:33, 21.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  12% 273M/2.24G [00:05<00:50, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  13% 283M/2.24G [00:05<00:57, 34.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  13% 283M/2.24G [00:05<00:50, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  13% 283M/2.24G [00:05<00:47, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  10% 231M/2.24G [00:05<01:34, 21.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  13% 294M/2.24G [00:05<01:00, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  13% 294M/2.24G [00:05<00:51, 37.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  13% 294M/2.24G [00:05<00:46, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  13% 294M/2.24G [00:05<00:43, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  14% 304M/2.24G [00:05<00:42, 46.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  14% 304M/2.24G [00:05<00:54, 35.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  11% 241M/2.24G [00:05<01:19, 25.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  14% 304M/2.24G [00:05<00:44, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  14% 304M/2.24G [00:05<00:42, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  14% 315M/2.24G [00:06<00:37, 50.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  11% 252M/2.24G [00:06<01:07, 29.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  14% 315M/2.24G [00:06<00:50, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  14% 315M/2.24G [00:05<00:41, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  14% 315M/2.24G [00:05<00:40, 47.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  14% 325M/2.24G [00:06<00:40, 48.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  15% 325M/2.24G [00:06<00:46, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  15% 325M/2.24G [00:05<00:37, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  12% 262M/2.24G [00:06<00:59, 33.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  14% 325M/2.24G [00:06<00:37, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  15% 336M/2.24G [00:06<00:38, 49.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  12% 273M/2.24G [00:06<00:52, 37.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  15% 336M/2.24G [00:06<00:38, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  15% 336M/2.24G [00:06<00:45, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  15% 336M/2.24G [00:06<00:36, 53.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  15% 346M/2.24G [00:06<00:36, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  15% 346M/2.24G [00:06<00:36, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  13% 283M/2.24G [00:06<00:48, 40.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  16% 357M/2.24G [00:06<00:31, 59.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  15% 346M/2.24G [00:06<00:41, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  15% 346M/2.24G [00:06<00:38, 48.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  16% 357M/2.24G [00:06<00:32, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  16% 367M/2.24G [00:06<00:29, 62.7MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  13% 294M/2.24G [00:07<00:45, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  16% 357M/2.24G [00:06<00:36, 52.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  16% 357M/2.24G [00:07<00:42, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  16% 367M/2.24G [00:06<00:31, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  14% 304M/2.24G [00:07<00:38, 50.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  17% 377M/2.24G [00:07<00:29, 62.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  16% 367M/2.24G [00:06<00:32, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  16% 367M/2.24G [00:07<00:35, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  17% 377M/2.24G [00:06<00:28, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  14% 315M/2.24G [00:07<00:32, 58.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  17% 388M/2.24G [00:07<00:29, 63.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  17% 377M/2.24G [00:07<00:33, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  15% 325M/2.24G [00:07<00:31, 61.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  17% 377M/2.24G [00:07<00:37, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  17% 388M/2.24G [00:06<00:33, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  18% 398M/2.24G [00:07<00:33, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  17% 388M/2.24G [00:07<00:35, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  15% 336M/2.24G [00:07<00:33, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  17% 388M/2.24G [00:07<00:36, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  18% 409M/2.24G [00:07<00:30, 60.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  18% 398M/2.24G [00:07<00:35, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  18% 398M/2.24G [00:07<00:33, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  15% 346M/2.24G [00:08<01:22, 23.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  18% 398M/2.24G [00:09<02:23, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  19% 419M/2.24G [00:09<02:16, 13.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  18% 409M/2.24G [00:09<02:19, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  16% 357M/2.24G [00:09<02:02, 15.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  18% 409M/2.24G [00:09<02:17, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  18% 409M/2.24G [00:09<01:47, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  19% 419M/2.24G [00:10<01:40, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  19% 430M/2.24G [00:10<01:42, 17.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  19% 419M/2.24G [00:09<01:44, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  19% 419M/2.24G [00:09<01:20, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  20% 440M/2.24G [00:10<01:16, 23.5MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  17% 377M/2.24G [00:10<01:14, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  19% 430M/2.24G [00:10<01:20, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  19% 430M/2.24G [00:09<01:22, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  19% 430M/2.24G [00:10<01:05, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  20% 451M/2.24G [00:10<01:02, 28.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  17% 388M/2.24G [00:10<01:03, 29.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  20% 440M/2.24G [00:10<00:51, 34.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  21% 461M/2.24G [00:10<00:49, 35.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  18% 398M/2.24G [00:10<00:52, 35.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  20% 440M/2.24G [00:10<01:09, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  20% 440M/2.24G [00:09<01:13, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  18% 409M/2.24G [00:10<00:43, 41.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  21% 472M/2.24G [00:10<00:42, 41.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  20% 451M/2.24G [00:10<00:45, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  20% 451M/2.24G [00:10<00:56, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  20% 451M/2.24G [00:10<00:59, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  19% 419M/2.24G [00:10<00:38, 47.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  21% 461M/2.24G [00:10<00:38, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  21% 482M/2.24G [00:10<00:37, 46.7MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  19% 430M/2.24G [00:10<00:33, 53.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  21% 461M/2.24G [00:10<00:49, 35.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  21% 461M/2.24G [00:10<00:50, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  21% 472M/2.24G [00:10<00:38, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 493M/2.24G [00:11<00:38, 46.0MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  20% 440M/2.24G [00:11<00:35, 50.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  21% 472M/2.24G [00:11<00:46, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  21% 472M/2.24G [00:10<00:47, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 503M/2.24G [00:11<00:35, 49.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  22% 482M/2.24G [00:11<00:38, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  21% 482M/2.24G [00:10<00:38, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  22% 482M/2.24G [00:10<00:38, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  20% 451M/2.24G [00:11<00:35, 51.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  23% 514M/2.24G [00:11<00:32, 54.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  22% 493M/2.24G [00:11<00:33, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  22% 493M/2.24G [00:11<00:34, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  21% 461M/2.24G [00:11<00:32, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  22% 493M/2.24G [00:10<00:37, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  23% 524M/2.24G [00:11<00:28, 59.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  23% 503M/2.24G [00:11<00:30, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  21% 472M/2.24G [00:11<00:29, 59.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  22% 503M/2.24G [00:11<00:35, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  24% 535M/2.24G [00:11<00:28, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  23% 514M/2.24G [00:11<00:28, 61.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  22% 503M/2.24G [00:11<00:35, 48.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  22% 482M/2.24G [00:11<00:25, 67.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  23% 514M/2.24G [00:11<00:31, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  23% 514M/2.24G [00:11<00:32, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  24% 545M/2.24G [00:11<00:28, 60.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  23% 524M/2.24G [00:11<00:29, 58.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  22% 493M/2.24G [00:11<00:26, 66.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  23% 524M/2.24G [00:11<00:27, 62.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  23% 524M/2.24G [00:13<02:08, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  24% 535M/2.24G [00:13<02:02, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  24% 535M/2.24G [00:13<02:04, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 556M/2.24G [00:14<02:08, 13.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  24% 545M/2.24G [00:13<01:14, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  25% 556M/2.24G [00:13<01:11, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 566M/2.24G [00:14<01:35, 17.5MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  22% 503M/2.24G [00:14<02:14, 12.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  25% 556M/2.24G [00:14<01:14, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  25% 556M/2.24G [00:13<01:02, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  25% 566M/2.24G [00:13<00:59, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  23% 514M/2.24G [00:14<01:42, 16.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  26% 577M/2.24G [00:14<01:15, 22.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  25% 566M/2.24G [00:14<01:02, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  26% 577M/2.24G [00:14<00:51, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  25% 566M/2.24G [00:13<00:53, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  23% 524M/2.24G [00:14<01:20, 21.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  26% 587M/2.24G [00:14<01:01, 26.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  26% 577M/2.24G [00:14<00:54, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  26% 587M/2.24G [00:14<00:44, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 598M/2.24G [00:14<00:48, 34.2MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  24% 535M/2.24G [00:14<01:03, 27.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  26% 587M/2.24G [00:14<00:45, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  26% 577M/2.24G [00:14<00:50, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  27% 598M/2.24G [00:14<00:39, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 608M/2.24G [00:14<00:40, 40.7MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  24% 545M/2.24G [00:14<00:56, 29.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  26% 587M/2.24G [00:14<00:47, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  27% 608M/2.24G [00:14<00:37, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 619M/2.24G [00:15<00:36, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  27% 598M/2.24G [00:14<00:44, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  27% 598M/2.24G [00:14<00:39, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  25% 556M/2.24G [00:15<00:49, 34.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  28% 619M/2.24G [00:14<00:36, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  27% 608M/2.24G [00:15<00:44, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 629M/2.24G [00:15<00:38, 42.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  25% 566M/2.24G [00:15<00:41, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  27% 608M/2.24G [00:14<00:37, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  28% 629M/2.24G [00:15<00:31, 50.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  28% 619M/2.24G [00:15<00:38, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 640M/2.24G [00:15<00:34, 47.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  26% 577M/2.24G [00:15<00:36, 45.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  28% 640M/2.24G [00:15<00:29, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  28% 619M/2.24G [00:14<00:35, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  26% 587M/2.24G [00:15<00:32, 50.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  29% 650M/2.24G [00:15<00:32, 48.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  28% 629M/2.24G [00:15<00:36, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  29% 650M/2.24G [00:15<00:27, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  28% 629M/2.24G [00:15<00:32, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  29% 661M/2.24G [00:15<00:26, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  29% 640M/2.24G [00:15<00:34, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  29% 661M/2.24G [00:15<00:35, 45.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  29% 640M/2.24G [00:15<00:32, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  27% 598M/2.24G [00:15<00:38, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  30% 671M/2.24G [00:15<00:25, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  29% 650M/2.24G [00:16<00:31, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  29% 650M/2.24G [00:15<00:28, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  30% 671M/2.24G [00:16<00:30, 51.0MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  27% 608M/2.24G [00:16<00:32, 49.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  30% 682M/2.24G [00:15<00:25, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  30% 682M/2.24G [00:16<00:27, 55.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  30% 661M/2.24G [00:16<00:31, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  29% 661M/2.24G [00:15<00:29, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  28% 619M/2.24G [00:16<00:31, 51.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  31% 692M/2.24G [00:15<00:22, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  31% 692M/2.24G [00:16<00:25, 60.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  30% 671M/2.24G [00:16<00:27, 57.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  31% 703M/2.24G [00:16<00:21, 71.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  28% 629M/2.24G [00:16<00:28, 56.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  30% 671M/2.24G [00:15<00:28, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  30% 682M/2.24G [00:16<00:24, 62.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  31% 703M/2.24G [00:16<00:24, 63.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  30% 682M/2.24G [00:16<00:32, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  32% 713M/2.24G [00:16<00:32, 47.2MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  29% 650M/2.24G [00:16<00:29, 53.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  31% 692M/2.24G [00:16<00:34, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  32% 724M/2.24G [00:16<00:26, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  31% 692M/2.24G [00:16<00:31, 49.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  31% 703M/2.24G [00:16<00:29, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  33% 734M/2.24G [00:16<00:24, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  32% 724M/2.24G [00:17<00:33, 45.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  29% 661M/2.24G [00:17<00:31, 50.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  31% 703M/2.24G [00:16<00:29, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  33% 744M/2.24G [00:16<00:24, 62.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  32% 713M/2.24G [00:17<00:29, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  33% 734M/2.24G [00:17<00:30, 49.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  32% 713M/2.24G [00:16<00:28, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  30% 671M/2.24G [00:17<00:31, 50.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  34% 755M/2.24G [00:16<00:22, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  32% 724M/2.24G [00:17<00:27, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  33% 744M/2.24G [00:17<00:28, 52.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  33% 734M/2.24G [00:17<00:26, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  32% 724M/2.24G [00:16<00:32, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  34% 755M/2.24G [00:17<00:25, 57.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  34% 765M/2.24G [00:17<00:27, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  33% 744M/2.24G [00:17<00:23, 62.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  35% 776M/2.24G [00:17<00:23, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  33% 734M/2.24G [00:17<00:28, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  34% 765M/2.24G [00:17<00:23, 62.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  30% 682M/2.24G [00:17<00:48, 32.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  33% 744M/2.24G [00:17<00:34, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  35% 786M/2.24G [00:17<00:31, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  34% 765M/2.24G [00:18<00:26, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  31% 692M/2.24G [00:18<01:00, 25.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  35% 786M/2.24G [00:18<00:42, 34.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  35% 797M/2.24G [00:18<00:46, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  35% 776M/2.24G [00:18<00:39, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  34% 755M/2.24G [00:18<00:51, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  31% 703M/2.24G [00:18<00:51, 30.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  36% 807M/2.24G [00:18<00:39, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  35% 786M/2.24G [00:18<00:36, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  36% 797M/2.24G [00:18<00:40, 36.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  34% 765M/2.24G [00:18<00:44, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  32% 713M/2.24G [00:19<00:45, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  36% 818M/2.24G [00:18<00:36, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  36% 797M/2.24G [00:19<00:35, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  36% 807M/2.24G [00:19<00:38, 37.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  35% 776M/2.24G [00:18<00:41, 35.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  32% 724M/2.24G [00:19<00:42, 36.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  37% 828M/2.24G [00:18<00:33, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  36% 807M/2.24G [00:19<00:33, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  36% 818M/2.24G [00:19<00:37, 38.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  35% 786M/2.24G [00:18<00:42, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  33% 734M/2.24G [00:19<00:39, 37.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  37% 839M/2.24G [00:19<00:33, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  37% 818M/2.24G [00:19<00:31, 44.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  37% 828M/2.24G [00:19<00:35, 39.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  36% 797M/2.24G [00:19<00:36, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  33% 744M/2.24G [00:19<00:39, 38.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  37% 828M/2.24G [00:19<00:31, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  38% 849M/2.24G [00:19<00:34, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  36% 807M/2.24G [00:19<00:33, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  37% 839M/2.24G [00:19<00:36, 38.7MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  34% 755M/2.24G [00:19<00:35, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  38% 839M/2.24G [00:19<00:29, 46.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  38% 860M/2.24G [00:19<00:31, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  37% 818M/2.24G [00:19<00:31, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  34% 765M/2.24G [00:20<00:30, 47.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  38% 849M/2.24G [00:20<00:35, 39.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  39% 870M/2.24G [00:19<00:29, 46.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  38% 849M/2.24G [00:20<00:29, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  37% 828M/2.24G [00:19<00:28, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  35% 776M/2.24G [00:20<00:29, 49.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  38% 860M/2.24G [00:20<00:29, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  38% 860M/2.24G [00:20<00:28, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  39% 881M/2.24G [00:20<00:29, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  37% 839M/2.24G [00:19<00:28, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  39% 870M/2.24G [00:20<00:28, 47.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  35% 786M/2.24G [00:20<00:31, 46.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  39% 870M/2.24G [00:20<00:27, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  40% 891M/2.24G [00:20<00:33, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  36% 797M/2.24G [00:20<00:30, 47.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  38% 849M/2.24G [00:20<00:34, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  39% 881M/2.24G [00:20<00:32, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  39% 881M/2.24G [00:20<00:27, 48.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  40% 902M/2.24G [00:21<01:01, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  36% 807M/2.24G [00:21<01:03, 22.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  38% 860M/2.24G [00:21<01:03, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 891M/2.24G [00:21<01:01, 22.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  40% 891M/2.24G [00:22<01:05, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  39% 870M/2.24G [00:21<00:53, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  41% 923M/2.24G [00:21<00:42, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 902M/2.24G [00:22<00:52, 25.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  37% 828M/2.24G [00:22<00:43, 32.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  39% 881M/2.24G [00:22<00:59, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  41% 912M/2.24G [00:24<01:52, 11.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  37% 839M/2.24G [00:24<01:42, 13.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  40% 891M/2.24G [00:23<01:42, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  41% 912M/2.24G [00:24<01:39, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  41% 923M/2.24G [00:24<01:25, 15.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  42% 933M/2.24G [00:23<01:39, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  40% 902M/2.24G [00:23<01:15, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  42% 933M/2.24G [00:24<01:03, 20.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  42% 944M/2.24G [00:24<01:17, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  38% 860M/2.24G [00:24<01:05, 21.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  42% 933M/2.24G [00:24<01:05, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  41% 912M/2.24G [00:23<00:59, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  43% 954M/2.24G [00:24<01:01, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  42% 944M/2.24G [00:24<00:51, 25.3MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  39% 870M/2.24G [00:24<00:55, 24.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  42% 944M/2.24G [00:24<00:56, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  41% 923M/2.24G [00:24<00:49, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 954M/2.24G [00:24<00:42, 30.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  43% 965M/2.24G [00:24<00:52, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  39% 881M/2.24G [00:24<00:48, 28.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  43% 954M/2.24G [00:24<00:47, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  42% 933M/2.24G [00:24<00:41, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 965M/2.24G [00:25<00:38, 33.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  43% 975M/2.24G [00:24<00:44, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  40% 891M/2.24G [00:25<00:42, 32.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  43% 965M/2.24G [00:25<00:42, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  42% 944M/2.24G [00:24<00:38, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  44% 986M/2.24G [00:24<00:37, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 975M/2.24G [00:25<00:33, 37.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  40% 902M/2.24G [00:25<00:36, 37.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  44% 975M/2.24G [00:25<00:37, 33.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  44% 996M/2.24G [00:25<00:32, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  43% 954M/2.24G [00:24<00:34, 37.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  41% 912M/2.24G [00:25<00:32, 40.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  44% 986M/2.24G [00:25<00:30, 40.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  44% 986M/2.24G [00:25<00:31, 40.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  45% 1.01G/2.24G [00:25<00:27, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  44% 996M/2.24G [00:25<00:27, 45.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  41% 923M/2.24G [00:25<00:29, 45.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  43% 965M/2.24G [00:25<00:31, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  45% 1.02G/2.24G [00:25<00:24, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  45% 996M/2.24G [00:25<00:30, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  42% 933M/2.24G [00:25<00:28, 45.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  44% 975M/2.24G [00:25<00:30, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  46% 1.03G/2.24G [00:25<00:23, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  45% 1.01G/2.24G [00:25<00:28, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  45% 1.01G/2.24G [00:25<00:26, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  42% 944M/2.24G [00:25<00:25, 51.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  46% 1.02G/2.24G [00:25<00:22, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  46% 1.04G/2.24G [00:25<00:21, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  45% 1.02G/2.24G [00:26<00:28, 43.2MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  43% 954M/2.24G [00:26<00:23, 54.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  44% 986M/2.24G [00:25<00:30, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  46% 1.03G/2.24G [00:26<00:22, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  47% 1.05G/2.24G [00:25<00:22, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  43% 965M/2.24G [00:26<00:24, 52.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  44% 996M/2.24G [00:25<00:28, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  46% 1.04G/2.24G [00:26<00:20, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 1.03G/2.24G [00:26<00:27, 43.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  47% 1.06G/2.24G [00:26<00:21, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  48% 1.07G/2.24G [00:26<00:18, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  47% 1.05G/2.24G [00:26<00:21, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  44% 975M/2.24G [00:26<00:24, 51.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  45% 1.01G/2.24G [00:25<00:27, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 1.04G/2.24G [00:26<00:27, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  47% 1.06G/2.24G [00:26<00:18, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  44% 986M/2.24G [00:26<00:22, 56.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  47% 1.05G/2.24G [00:26<00:23, 50.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  45% 1.02G/2.24G [00:26<00:24, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  48% 1.08G/2.24G [00:26<00:22, 51.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  46% 1.03G/2.24G [00:26<00:21, 56.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  48% 1.07G/2.24G [00:26<00:19, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  47% 1.06G/2.24G [00:26<00:21, 56.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  44% 996M/2.24G [00:26<00:21, 58.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  48% 1.07G/2.24G [00:26<00:18, 64.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  49% 1.10G/2.24G [00:26<00:17, 66.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  46% 1.04G/2.24G [00:26<00:21, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  48% 1.08G/2.24G [00:27<00:19, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  45% 1.01G/2.24G [00:27<00:24, 51.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  48% 1.08G/2.24G [00:27<00:18, 63.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  50% 1.11G/2.24G [00:26<00:16, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  47% 1.05G/2.24G [00:26<00:19, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  49% 1.09G/2.24G [00:27<00:16, 70.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  47% 1.06G/2.24G [00:26<00:18, 65.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  50% 1.12G/2.24G [00:26<00:16, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  46% 1.03G/2.24G [00:27<00:19, 60.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  50% 1.13G/2.24G [00:27<00:16, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  49% 1.10G/2.24G [00:27<00:19, 58.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  48% 1.07G/2.24G [00:26<00:19, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  48% 1.08G/2.24G [00:27<00:19, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  46% 1.04G/2.24G [00:27<00:24, 49.5MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  50% 1.12G/2.24G [00:27<00:16, 66.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  51% 1.15G/2.24G [00:27<00:15, 70.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  49% 1.09G/2.24G [00:27<00:16, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  47% 1.06G/2.24G [00:27<00:19, 60.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  52% 1.16G/2.24G [00:27<00:17, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  49% 1.09G/2.24G [00:27<00:45, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  50% 1.13G/2.24G [00:28<00:19, 56.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  49% 1.10G/2.24G [00:28<00:52, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  51% 1.14G/2.24G [00:30<01:19, 13.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  50% 1.11G/2.24G [00:29<01:20, 14.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  52% 1.17G/2.24G [00:30<01:16, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  49% 1.10G/2.24G [00:30<01:49, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  53% 1.18G/2.24G [00:30<00:58, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  50% 1.12G/2.24G [00:29<01:00, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  52% 1.16G/2.24G [00:30<00:48, 22.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  50% 1.12G/2.24G [00:30<01:01, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  48% 1.07G/2.24G [00:30<01:22, 14.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  53% 1.20G/2.24G [00:30<00:45, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  52% 1.17G/2.24G [00:30<00:40, 26.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  51% 1.13G/2.24G [00:30<00:49, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  48% 1.08G/2.24G [00:30<01:07, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  51% 1.13G/2.24G [00:30<00:53, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  54% 1.21G/2.24G [00:30<00:37, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  53% 1.18G/2.24G [00:31<00:38, 27.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  54% 1.22G/2.24G [00:30<00:32, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  49% 1.09G/2.24G [00:31<00:57, 19.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  51% 1.14G/2.24G [00:30<00:44, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  51% 1.14G/2.24G [00:31<00:46, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  55% 1.23G/2.24G [00:30<00:27, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  51% 1.15G/2.24G [00:30<00:37, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  53% 1.20G/2.24G [00:31<00:35, 29.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  49% 1.10G/2.24G [00:31<00:48, 23.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  52% 1.15G/2.24G [00:31<00:41, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  55% 1.24G/2.24G [00:31<00:26, 38.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  54% 1.21G/2.24G [00:31<00:30, 33.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  52% 1.16G/2.24G [00:30<00:32, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  50% 1.11G/2.24G [00:31<00:41, 27.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  52% 1.16G/2.24G [00:31<00:35, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  56% 1.25G/2.24G [00:31<00:23, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  52% 1.17G/2.24G [00:31<00:29, 36.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  54% 1.22G/2.24G [00:31<00:29, 35.4MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  50% 1.12G/2.24G [00:31<00:37, 30.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  53% 1.17G/2.24G [00:31<00:32, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  56% 1.26G/2.24G [00:31<00:22, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  55% 1.23G/2.24G [00:32<00:26, 38.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  51% 1.13G/2.24G [00:32<00:31, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  53% 1.18G/2.24G [00:31<00:28, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  53% 1.18G/2.24G [00:32<00:28, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  57% 1.27G/2.24G [00:31<00:21, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  51% 1.14G/2.24G [00:32<00:30, 36.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  53% 1.20G/2.24G [00:31<00:27, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  55% 1.24G/2.24G [00:32<00:26, 37.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  53% 1.20G/2.24G [00:32<00:27, 38.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  57% 1.28G/2.24G [00:31<00:20, 46.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  51% 1.15G/2.24G [00:32<00:28, 38.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  54% 1.21G/2.24G [00:31<00:26, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  57% 1.29G/2.24G [00:32<00:20, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 1.25G/2.24G [00:32<00:25, 39.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  54% 1.21G/2.24G [00:32<00:25, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  52% 1.16G/2.24G [00:32<00:28, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  54% 1.22G/2.24G [00:32<00:25, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  58% 1.30G/2.24G [00:32<00:21, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  54% 1.22G/2.24G [00:32<00:27, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 1.26G/2.24G [00:32<00:25, 38.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  58% 1.31G/2.24G [00:32<00:21, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  52% 1.17G/2.24G [00:33<00:28, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  55% 1.23G/2.24G [00:33<00:26, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  55% 1.23G/2.24G [00:32<00:27, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.27G/2.24G [00:33<00:26, 37.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  59% 1.32G/2.24G [00:32<00:22, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  53% 1.18G/2.24G [00:33<00:28, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  55% 1.24G/2.24G [00:33<00:26, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  55% 1.24G/2.24G [00:32<00:26, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.28G/2.24G [00:33<00:25, 38.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  59% 1.33G/2.24G [00:33<00:21, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  56% 1.25G/2.24G [00:32<00:24, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  53% 1.20G/2.24G [00:33<00:27, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  56% 1.25G/2.24G [00:33<00:25, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.29G/2.24G [00:33<00:25, 38.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  60% 1.34G/2.24G [00:33<00:20, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  56% 1.26G/2.24G [00:33<00:22, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  54% 1.21G/2.24G [00:33<00:24, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  56% 1.26G/2.24G [00:33<00:22, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  58% 1.30G/2.24G [00:33<00:22, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  60% 1.35G/2.24G [00:33<00:17, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  57% 1.27G/2.24G [00:33<00:21, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  54% 1.22G/2.24G [00:34<00:23, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  57% 1.27G/2.24G [00:34<00:21, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  58% 1.31G/2.24G [00:34<00:21, 43.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  61% 1.36G/2.24G [00:33<00:18, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  57% 1.28G/2.24G [00:34<00:22, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  55% 1.23G/2.24G [00:34<00:24, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  57% 1.28G/2.24G [00:33<00:23, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  59% 1.32G/2.24G [00:34<00:22, 41.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  61% 1.37G/2.24G [00:34<00:19, 44.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  55% 1.24G/2.24G [00:34<00:23, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  58% 1.29G/2.24G [00:33<00:22, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  58% 1.29G/2.24G [00:34<00:22, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  59% 1.33G/2.24G [00:34<00:21, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  62% 1.38G/2.24G [00:34<00:19, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  58% 1.30G/2.24G [00:38<02:02, 7.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  62% 1.39G/2.24G [00:38<01:48, 7.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  56% 1.25G/2.24G [00:38<02:10, 7.59MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  58% 1.30G/2.24G [00:37<02:03, 7.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  59% 1.32G/2.24G [00:38<01:08, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  63% 1.42G/2.24G [00:38<01:00, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  59% 1.32G/2.24G [00:38<01:09, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  60% 1.34G/2.24G [00:38<02:04, 7.27MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  57% 1.27G/2.24G [00:38<01:14, 13.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  60% 1.33G/2.24G [00:38<00:53, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  64% 1.43G/2.24G [00:38<00:48, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  57% 1.28G/2.24G [00:38<00:59, 16.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  59% 1.33G/2.24G [00:38<00:56, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  60% 1.34G/2.24G [00:38<00:41, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  60% 1.35G/2.24G [00:39<01:31, 9.75MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  58% 1.29G/2.24G [00:39<00:46, 20.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  61% 1.35G/2.24G [00:39<00:33, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  64% 1.44G/2.24G [00:38<00:39, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  60% 1.34G/2.24G [00:38<00:45, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  61% 1.36G/2.24G [00:39<01:08, 12.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  58% 1.30G/2.24G [00:39<00:37, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  61% 1.36G/2.24G [00:39<00:27, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  64% 1.45G/2.24G [00:39<00:32, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  61% 1.37G/2.24G [00:39<00:51, 17.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  60% 1.35G/2.24G [00:38<00:37, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  58% 1.31G/2.24G [00:39<00:30, 30.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  61% 1.37G/2.24G [00:39<00:22, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  65% 1.46G/2.24G [00:39<00:26, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  61% 1.36G/2.24G [00:38<00:31, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  62% 1.38G/2.24G [00:39<00:40, 21.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  62% 1.38G/2.24G [00:39<00:20, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  59% 1.32G/2.24G [00:39<00:26, 34.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  65% 1.47G/2.24G [00:39<00:22, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  62% 1.39G/2.24G [00:39<00:31, 26.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  61% 1.37G/2.24G [00:39<00:27, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  59% 1.33G/2.24G [00:39<00:23, 38.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  62% 1.39G/2.24G [00:39<00:19, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  66% 1.48G/2.24G [00:39<00:20, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  63% 1.41G/2.24G [00:39<00:26, 32.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  62% 1.38G/2.24G [00:39<00:23, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  60% 1.34G/2.24G [00:40<00:20, 44.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  63% 1.41G/2.24G [00:40<00:18, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  66% 1.49G/2.24G [00:39<00:17, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  63% 1.42G/2.24G [00:40<00:21, 38.2MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  60% 1.35G/2.24G [00:40<00:18, 48.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  62% 1.39G/2.24G [00:39<00:21, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 1.43G/2.24G [00:40<00:19, 42.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  63% 1.42G/2.24G [00:40<00:17, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  67% 1.50G/2.24G [00:39<00:16, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  61% 1.36G/2.24G [00:40<00:15, 56.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  63% 1.41G/2.24G [00:39<00:19, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  61% 1.37G/2.24G [00:40<00:14, 59.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  67% 1.51G/2.24G [00:40<00:15, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  64% 1.43G/2.24G [00:40<00:16, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 1.45G/2.24G [00:40<00:14, 56.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  63% 1.42G/2.24G [00:39<00:16, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  68% 1.52G/2.24G [00:40<00:13, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  62% 1.38G/2.24G [00:40<00:14, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  64% 1.43G/2.24G [00:40<00:14, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  62% 1.39G/2.24G [00:40<00:12, 66.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  64% 1.44G/2.24G [00:40<00:17, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  69% 1.54G/2.24G [00:40<00:09, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  65% 1.46G/2.24G [00:40<00:19, 41.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  64% 1.44G/2.24G [00:40<00:16, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  63% 1.41G/2.24G [00:41<00:16, 51.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  69% 1.55G/2.24G [00:40<00:12, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  65% 1.45G/2.24G [00:41<00:19, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  65% 1.47G/2.24G [00:41<00:18, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  65% 1.45G/2.24G [00:40<00:17, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  65% 1.46G/2.24G [00:41<00:17, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  63% 1.42G/2.24G [00:41<00:17, 48.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  70% 1.57G/2.24G [00:40<00:10, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  66% 1.48G/2.24G [00:41<00:17, 44.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  66% 1.47G/2.24G [00:41<00:15, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  65% 1.46G/2.24G [00:40<00:16, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  71% 1.58G/2.24G [00:41<00:09, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  64% 1.43G/2.24G [00:41<00:15, 52.5MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  66% 1.49G/2.24G [00:41<00:14, 51.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  66% 1.48G/2.24G [00:41<00:13, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  71% 1.59G/2.24G [00:41<00:08, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  66% 1.47G/2.24G [00:40<00:14, 52.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  67% 1.50G/2.24G [00:41<00:15, 47.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  64% 1.44G/2.24G [00:41<00:19, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  71% 1.60G/2.24G [00:41<00:10, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  66% 1.48G/2.24G [00:41<00:16, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  67% 1.49G/2.24G [00:41<00:17, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  72% 1.61G/2.24G [00:41<00:09, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  65% 1.45G/2.24G [00:41<00:17, 45.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  67% 1.51G/2.24G [00:42<00:15, 46.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  66% 1.49G/2.24G [00:41<00:14, 50.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  72% 1.63G/2.24G [00:41<00:08, 71.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  66% 1.47G/2.24G [00:42<00:13, 59.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  67% 1.50G/2.24G [00:41<00:14, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  68% 1.53G/2.24G [00:42<00:13, 53.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  73% 1.64G/2.24G [00:42<00:10, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  67% 1.51G/2.24G [00:41<00:13, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  66% 1.48G/2.24G [00:42<00:12, 59.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  73% 1.65G/2.24G [00:42<00:10, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  69% 1.54G/2.24G [00:42<00:13, 53.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  66% 1.49G/2.24G [00:42<00:12, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  68% 1.52G/2.24G [00:41<00:13, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  74% 1.66G/2.24G [00:42<00:09, 59.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  69% 1.55G/2.24G [00:42<00:12, 56.4MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  67% 1.50G/2.24G [00:42<00:11, 61.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  68% 1.53G/2.24G [00:42<00:11, 59.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  74% 1.67G/2.24G [00:42<00:09, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  70% 1.56G/2.24G [00:42<00:11, 59.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  67% 1.50G/2.24G [00:42<00:32, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  67% 1.51G/2.24G [00:42<00:12, 59.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  75% 1.68G/2.24G [00:42<00:13, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  69% 1.54G/2.24G [00:42<00:19, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  68% 1.51G/2.24G [00:43<00:32, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  70% 1.57G/2.24G [00:43<00:18, 35.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  75% 1.69G/2.24G [00:43<00:12, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  68% 1.52G/2.24G [00:43<00:19, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  69% 1.55G/2.24G [00:42<00:17, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  68% 1.52G/2.24G [00:43<00:26, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  76% 1.70G/2.24G [00:43<00:11, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  70% 1.56G/2.24G [00:43<00:15, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  68% 1.53G/2.24G [00:43<00:18, 38.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  71% 1.58G/2.24G [00:43<00:18, 36.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  76% 1.71G/2.24G [00:43<00:09, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  71% 1.59G/2.24G [00:43<00:14, 44.3MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  69% 1.54G/2.24G [00:43<00:15, 44.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  70% 1.57G/2.24G [00:43<00:14, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  77% 1.72G/2.24G [00:43<00:08, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  68% 1.53G/2.24G [00:43<00:26, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  69% 1.55G/2.24G [00:43<00:13, 49.7MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  71% 1.60G/2.24G [00:44<00:13, 47.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  71% 1.58G/2.24G [00:43<00:12, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  77% 1.73G/2.24G [00:43<00:07, 65.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  78% 1.74G/2.24G [00:43<00:08, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  71% 1.59G/2.24G [00:43<00:13, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  70% 1.56G/2.24G [00:44<00:14, 46.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  69% 1.55G/2.24G [00:44<00:18, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  72% 1.61G/2.24G [00:44<00:14, 44.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  72% 1.60G/2.24G [00:43<00:11, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  70% 1.57G/2.24G [00:44<00:12, 54.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  78% 1.76G/2.24G [00:44<00:06, 71.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  70% 1.56G/2.24G [00:44<00:18, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  71% 1.58G/2.24G [00:44<00:12, 51.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  72% 1.61G/2.24G [00:43<00:12, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  72% 1.63G/2.24G [00:44<00:15, 38.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  79% 1.77G/2.24G [00:44<00:07, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  71% 1.59G/2.24G [00:46<00:36, 17.7MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  73% 1.64G/2.24G [00:46<00:48, 12.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  79% 1.78G/2.24G [00:46<00:29, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  71% 1.58G/2.24G [00:46<00:38, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  73% 1.63G/2.24G [00:46<00:46, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  72% 1.60G/2.24G [00:46<00:37, 16.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  73% 1.65G/2.24G [00:46<00:35, 17.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  72% 1.61G/2.24G [00:46<00:28, 22.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  71% 1.59G/2.24G [00:46<00:31, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  73% 1.64G/2.24G [00:46<00:34, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  80% 1.79G/2.24G [00:46<00:23, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  74% 1.66G/2.24G [00:47<00:26, 21.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  73% 1.63G/2.24G [00:47<00:22, 27.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  73% 1.65G/2.24G [00:46<00:26, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  72% 1.60G/2.24G [00:47<00:26, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  80% 1.80G/2.24G [00:46<00:18, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  74% 1.67G/2.24G [00:47<00:21, 27.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  73% 1.64G/2.24G [00:47<00:18, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  72% 1.61G/2.24G [00:47<00:21, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  74% 1.66G/2.24G [00:46<00:21, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  81% 1.81G/2.24G [00:47<00:15, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  75% 1.68G/2.24G [00:47<00:17, 32.5MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  73% 1.65G/2.24G [00:47<00:15, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  73% 1.63G/2.24G [00:47<00:18, 33.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  74% 1.67G/2.24G [00:46<00:18, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  81% 1.82G/2.24G [00:47<00:12, 32.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  74% 1.66G/2.24G [00:47<00:13, 43.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  75% 1.69G/2.24G [00:47<00:15, 36.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  73% 1.64G/2.24G [00:47<00:16, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  82% 1.84G/2.24G [00:47<00:10, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  74% 1.67G/2.24G [00:47<00:11, 48.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  75% 1.68G/2.24G [00:47<00:17, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  76% 1.70G/2.24G [00:47<00:14, 37.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  74% 1.65G/2.24G [00:47<00:14, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  82% 1.85G/2.24G [00:47<00:10, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  75% 1.68G/2.24G [00:47<00:11, 47.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  75% 1.69G/2.24G [00:47<00:14, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  76% 1.71G/2.24G [00:48<00:12, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  74% 1.66G/2.24G [00:47<00:12, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  83% 1.86G/2.24G [00:47<00:08, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  75% 1.69G/2.24G [00:48<00:11, 49.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  76% 1.70G/2.24G [00:47<00:12, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  75% 1.67G/2.24G [00:48<00:11, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 1.72G/2.24G [00:48<00:11, 46.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  83% 1.87G/2.24G [00:47<00:07, 51.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  76% 1.70G/2.24G [00:48<00:09, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  76% 1.71G/2.24G [00:47<00:11, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  75% 1.68G/2.24G [00:48<00:11, 50.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 1.73G/2.24G [00:48<00:10, 48.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  84% 1.88G/2.24G [00:48<00:07, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  76% 1.71G/2.24G [00:48<00:10, 52.6MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  78% 1.74G/2.24G [00:48<00:09, 54.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  77% 1.72G/2.24G [00:47<00:10, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  76% 1.70G/2.24G [00:48<00:08, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  84% 1.89G/2.24G [00:48<00:06, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  77% 1.72G/2.24G [00:48<00:09, 54.4MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  78% 1.75G/2.24G [00:48<00:08, 55.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  77% 1.73G/2.24G [00:48<00:10, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  76% 1.71G/2.24G [00:48<00:07, 67.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  78% 1.74G/2.24G [00:48<00:08, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  78% 1.76G/2.24G [00:48<00:08, 57.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  77% 1.72G/2.24G [00:48<00:07, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  85% 1.90G/2.24G [00:48<00:07, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  85% 1.91G/2.24G [00:48<00:05, 56.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  77% 1.73G/2.24G [00:49<00:11, 45.0MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  79% 1.77G/2.24G [00:49<00:08, 58.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  77% 1.73G/2.24G [00:49<00:07, 63.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  78% 1.75G/2.24G [00:48<00:09, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  85% 1.92G/2.24G [00:48<00:05, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  78% 1.74G/2.24G [00:49<00:09, 50.7MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  79% 1.78G/2.24G [00:49<00:08, 55.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  78% 1.74G/2.24G [00:49<00:08, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  78% 1.75G/2.24G [00:49<00:08, 56.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  79% 1.76G/2.24G [00:48<00:09, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  86% 1.93G/2.24G [00:49<00:05, 58.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  78% 1.75G/2.24G [00:49<00:07, 63.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  80% 1.79G/2.24G [00:49<00:08, 56.1MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  79% 1.76G/2.24G [00:49<00:08, 55.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  86% 1.94G/2.24G [00:49<00:05, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  79% 1.77G/2.24G [00:48<00:09, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  79% 1.76G/2.24G [00:49<00:07, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  80% 1.80G/2.24G [00:49<00:07, 56.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  79% 1.77G/2.24G [00:49<00:07, 61.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  87% 1.95G/2.24G [00:49<00:04, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  80% 1.78G/2.24G [00:49<00:09, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  79% 1.77G/2.24G [00:49<00:07, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  80% 1.78G/2.24G [00:49<00:07, 60.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  81% 1.81G/2.24G [00:49<00:08, 52.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  87% 1.96G/2.24G [00:49<00:05, 56.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  80% 1.79G/2.24G [00:50<00:07, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  80% 1.79G/2.24G [00:49<00:09, 46.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  80% 1.78G/2.24G [00:50<00:08, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  81% 1.82G/2.24G [00:50<00:08, 50.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  88% 1.97G/2.24G [00:49<00:04, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  80% 1.80G/2.24G [00:50<00:08, 54.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  82% 1.84G/2.24G [00:50<00:07, 51.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  80% 1.79G/2.24G [00:50<00:08, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  88% 1.98G/2.24G [00:49<00:05, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  81% 1.80G/2.24G [00:49<00:10, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  81% 1.81G/2.24G [00:50<00:07, 54.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  81% 1.80G/2.24G [00:50<00:08, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  89% 1.99G/2.24G [00:50<00:04, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  82% 1.85G/2.24G [00:50<00:08, 46.2MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  81% 1.82G/2.24G [00:50<00:07, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  81% 1.81G/2.24G [00:49<00:10, 40.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  81% 1.81G/2.24G [00:50<00:07, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  81% 1.82G/2.24G [00:50<00:08, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  83% 1.86G/2.24G [00:50<00:08, 45.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  82% 1.82G/2.24G [00:50<00:07, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  82% 1.84G/2.24G [00:50<00:08, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  89% 2.00G/2.24G [00:50<00:05, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  82% 1.84G/2.24G [00:51<00:18, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  82% 1.85G/2.24G [00:51<00:16, 24.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  82% 1.84G/2.24G [00:51<00:16, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  90% 2.01G/2.24G [00:51<00:10, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  83% 1.85G/2.24G [00:51<00:13, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  83% 1.86G/2.24G [00:52<00:13, 28.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  83% 1.86G/2.24G [00:51<00:11, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  90% 2.02G/2.24G [00:51<00:08, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  83% 1.86G/2.24G [00:52<00:10, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  83% 1.87G/2.24G [00:52<00:11, 33.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  91% 2.03G/2.24G [00:51<00:06, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  83% 1.87G/2.24G [00:51<00:09, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  83% 1.87G/2.24G [00:52<00:09, 40.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  84% 1.88G/2.24G [00:52<00:09, 40.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  91% 2.04G/2.24G [00:52<00:05, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  84% 1.88G/2.24G [00:51<00:08, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  84% 1.88G/2.24G [00:52<00:08, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  84% 1.89G/2.24G [00:52<00:08, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  92% 2.06G/2.24G [00:52<00:04, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  84% 1.89G/2.24G [00:51<00:08, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  83% 1.87G/2.24G [00:52<00:26, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  84% 1.89G/2.24G [00:53<00:12, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  85% 1.90G/2.24G [00:53<00:15, 21.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  92% 2.07G/2.24G [00:54<00:13, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  84% 1.88G/2.24G [00:55<00:43, 8.48MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  85% 1.90G/2.24G [00:55<00:34, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  85% 1.90G/2.24G [00:57<00:46, 7.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  85% 1.91G/2.24G [00:57<00:44, 7.43MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  92% 2.08G/2.24G [00:56<00:20, 8.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  84% 1.89G/2.24G [00:57<00:50, 7.06MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  85% 1.91G/2.24G [00:57<00:33, 9.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  86% 1.92G/2.24G [00:57<00:32, 9.98MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  85% 1.91G/2.24G [00:56<00:38, 8.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  85% 1.90G/2.24G [00:57<00:36, 9.52MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  93% 2.09G/2.24G [00:57<00:14, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  86% 1.92G/2.24G [00:57<00:24, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  93% 2.10G/2.24G [00:57<00:10, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  85% 1.91G/2.24G [00:57<00:26, 12.5MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  86% 1.93G/2.24G [00:57<00:24, 13.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  86% 1.92G/2.24G [00:57<00:28, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  94% 2.11G/2.24G [00:57<00:07, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  85% 1.92G/2.24G [00:57<00:19, 16.7MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  87% 1.94G/2.24G [00:57<00:17, 17.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  86% 1.93G/2.24G [00:57<00:20, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  94% 2.12G/2.24G [00:57<00:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  86% 1.93G/2.24G [00:57<00:14, 21.8MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  87% 1.95G/2.24G [00:57<00:12, 22.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  87% 1.94G/2.24G [00:57<00:15, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  95% 2.13G/2.24G [00:57<00:03, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  87% 1.95G/2.24G [00:58<00:08, 34.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  88% 1.96G/2.24G [00:58<00:10, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  88% 1.96G/2.24G [00:57<00:09, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  95% 2.14G/2.24G [00:57<00:02, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  88% 1.97G/2.24G [00:58<00:07, 35.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  87% 1.96G/2.24G [00:58<00:07, 35.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  96% 2.15G/2.24G [00:58<00:02, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  88% 1.97G/2.24G [00:57<00:08, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  88% 1.98G/2.24G [00:58<00:07, 36.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  86% 1.93G/2.24G [00:58<00:24, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  88% 1.97G/2.24G [01:01<00:26, 10.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  96% 2.16G/2.24G [01:01<00:09, 8.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  88% 1.98G/2.24G [01:01<00:30, 8.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  97% 2.17G/2.24G [01:02<00:08, 8.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  88% 1.98G/2.24G [01:03<00:30, 8.59MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  89% 1.99G/2.24G [01:02<00:27, 9.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  97% 2.18G/2.24G [01:02<00:05, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  90% 2.01G/2.24G [01:02<00:14, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  89% 2.00G/2.24G [01:03<00:16, 14.6MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  89% 1.99G/2.24G [01:03<00:39, 6.24MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  87% 1.94G/2.24G [01:03<00:58, 5.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  98% 2.20G/2.24G [01:03<00:02, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  90% 2.02G/2.24G [01:02<00:11, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  90% 2.01G/2.24G [01:03<00:13, 17.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  87% 1.95G/2.24G [01:03<00:40, 6.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  99% 2.21G/2.24G [01:03<00:01, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  89% 2.00G/2.24G [01:03<00:28, 8.35MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  91% 2.03G/2.24G [01:03<00:09, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  90% 2.02G/2.24G [01:03<00:10, 21.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  88% 1.96G/2.24G [01:03<00:28, 9.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  99% 2.22G/2.24G [01:03<00:00, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  90% 2.01G/2.24G [01:03<00:20, 11.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  88% 1.97G/2.24G [01:03<00:20, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 2.03G/2.24G [01:03<00:08, 25.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  91% 2.04G/2.24G [01:03<00:07, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  90% 2.02G/2.24G [01:03<00:14, 15.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  89% 1.98G/2.24G [01:03<00:14, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin:  99% 2.23G/2.24G [01:03<00:00, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 2.04G/2.24G [01:04<00:06, 29.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  92% 2.06G/2.24G [01:03<00:06, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  91% 2.03G/2.24G [01:04<00:10, 19.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  89% 1.99G/2.24G [01:04<00:10, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin: 100% 2.24G/2.24G [01:03<00:00, 36.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  92% 2.07G/2.24G [01:03<00:04, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin: 100% 2.24G/2.24G [01:04<00:00, 35.1MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/pytorch_model.bin\n",
            "\n",
            "\n",
            "flax_model.msgpack:  91% 2.04G/2.24G [01:04<00:08, 23.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  90% 2.00G/2.24G [01:04<00:08, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  92% 2.07G/2.24G [01:04<00:04, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  93% 2.08G/2.24G [01:03<00:04, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  92% 2.06G/2.24G [01:04<00:06, 30.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  90% 2.01G/2.24G [01:04<00:07, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  92% 2.08G/2.24G [01:04<00:03, 44.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  93% 2.09G/2.24G [01:03<00:03, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  92% 2.07G/2.24G [01:04<00:04, 35.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  91% 2.02G/2.24G [01:04<00:05, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  93% 2.09G/2.24G [01:04<00:03, 49.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  94% 2.10G/2.24G [01:04<00:02, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  93% 2.08G/2.24G [01:04<00:03, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  91% 2.03G/2.24G [01:04<00:04, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  94% 2.11G/2.24G [01:04<00:02, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  93% 2.10G/2.24G [01:04<00:02, 53.7MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  93% 2.09G/2.24G [01:04<00:03, 47.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  91% 2.04G/2.24G [01:04<00:03, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  94% 2.11G/2.24G [01:05<00:02, 58.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  95% 2.12G/2.24G [01:04<00:02, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  92% 2.06G/2.24G [01:05<00:03, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  94% 2.10G/2.24G [01:05<00:02, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  95% 2.13G/2.24G [01:04<00:01, 64.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  94% 2.12G/2.24G [01:05<00:01, 63.4MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  94% 2.11G/2.24G [01:05<00:02, 59.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  95% 2.14G/2.24G [01:04<00:01, 66.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  95% 2.13G/2.24G [01:05<00:01, 63.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  93% 2.08G/2.24G [01:05<00:02, 66.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  95% 2.12G/2.24G [01:05<00:01, 61.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  96% 2.15G/2.24G [01:04<00:01, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  95% 2.13G/2.24G [01:05<00:01, 67.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  96% 2.15G/2.24G [01:05<00:01, 80.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  96% 2.16G/2.24G [01:05<00:01, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  94% 2.10G/2.24G [01:05<00:02, 66.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  96% 2.16G/2.24G [01:05<00:01, 71.5MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  95% 2.14G/2.24G [01:05<00:01, 57.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  97% 2.17G/2.24G [01:05<00:01, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  94% 2.11G/2.24G [01:05<00:01, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  97% 2.17G/2.24G [01:05<00:01, 70.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  97% 2.18G/2.24G [01:05<00:00, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  95% 2.12G/2.24G [01:05<00:01, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  96% 2.16G/2.24G [01:05<00:01, 70.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  97% 2.18G/2.24G [01:06<00:00, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  98% 2.19G/2.24G [01:05<00:00, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  95% 2.13G/2.24G [01:06<00:01, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  98% 2.19G/2.24G [01:06<00:00, 74.0MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  97% 2.17G/2.24G [01:06<00:01, 66.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  96% 2.14G/2.24G [01:06<00:01, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  98% 2.20G/2.24G [01:05<00:00, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  98% 2.20G/2.24G [01:06<00:00, 70.4MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  97% 2.18G/2.24G [01:06<00:00, 64.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  96% 2.15G/2.24G [01:06<00:01, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  99% 2.21G/2.24G [01:05<00:00, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  99% 2.21G/2.24G [01:06<00:00, 64.9MB/s]\u001b[A\n",
            "\n",
            "flax_model.msgpack:  98% 2.19G/2.24G [01:06<00:00, 62.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  97% 2.16G/2.24G [01:06<00:01, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5:  99% 2.22G/2.24G [01:05<00:00, 65.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  98% 2.20G/2.24G [01:06<00:00, 63.0MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  99% 2.22G/2.24G [01:06<00:00, 62.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  97% 2.17G/2.24G [01:06<00:00, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5: 100% 2.23G/2.24G [01:06<00:00, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "flax_model.msgpack:  99% 2.21G/2.24G [01:06<00:00, 64.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  99% 2.23G/2.24G [01:06<00:00, 62.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5: 100% 2.24G/2.24G [01:06<00:00, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tf_model.h5: 100% 2.24G/2.24G [01:06<00:00, 33.8MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/tf_model.h5\n",
            "\n",
            "\n",
            "flax_model.msgpack:  99% 2.22G/2.24G [01:06<00:00, 65.3MB/s]\u001b[A\u001b[A\n",
            "model.safetensors: 100% 2.24G/2.24G [01:07<00:00, 64.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  98% 2.19G/2.24G [01:07<00:00, 68.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 2.24G/2.24G [01:07<00:00, 33.4MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/model.safetensors\n",
            "flax_model.msgpack: 100% 2.24G/2.24G [01:07<00:00, 33.3MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/flax_model.msgpack\n",
            "Fetching 17 files:  24% 4/17 [01:07<03:56, 18.22s/it]\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data:  99% 2.20G/2.24G [01:07<00:01, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.onnx_data: 100% 2.24G/2.24G [01:07<00:00, 32.9MB/s]\n",
            "Download complete. Moving file to FacebookAI/xlm-roberta-large/onnx/model.onnx_data\n",
            "Fetching 17 files: 100% 17/17 [01:08<00:00,  4.01s/it]\n",
            "/content/GPT-SoVITS/FacebookAI/xlm-roberta-large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title launch WebUI ÂêØÂä®WebUI\n",
        "!/usr/local/bin/pip install ipykernel\n",
        "!sed -i '10s/False/True/' /content/GPT-SoVITS/config.py\n",
        "%cd /content/GPT-SoVITS/\n",
        "!/usr/local/bin/python  webui.py"
      ],
      "metadata": {
        "id": "4oRGUzkrk8C7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e071892-e954-454d-fada-0f9ea2455799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/site-packages (6.29.5)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.9/site-packages (from ipykernel) (1.8.12)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (8.18.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/site-packages (from ipykernel) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.9/site-packages (from ipykernel) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/site-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from ipykernel) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from ipykernel) (7.0.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.9/site-packages (from ipykernel) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.9/site-packages (from ipykernel) (5.14.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.21.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
            "/content/GPT-SoVITS\n",
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://f59c1008fc27467ab3.gradio.live\n"
          ]
        }
      ]
    }
  ]
}